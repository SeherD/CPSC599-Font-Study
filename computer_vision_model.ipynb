{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "import zipfile as zipfile\n",
        "\n",
        "\n",
        "# Destination directories for storing the downloaded data\n",
        "supervised_dest_dir = 'supervised'\n",
        "unsupervised_synthetic_dest_dir = 'unsupervised_synthetic'\n",
        "unsupervised_dest_dir = 'unsupervised'\n",
        "\n",
        "# Create destination directories if they don't exist\n",
        "os.makedirs(supervised_dest_dir, exist_ok=True)\n",
        "os.makedirs(unsupervised_synthetic_dest_dir, exist_ok=True)\n",
        "os.makedirs(unsupervised_dest_dir, exist_ok=True)\n",
        "\n",
        "# Function to download a folder from Google Drive\n",
        "def download_folder(zip_name,destination):\n",
        "\n",
        "    with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
        "        zip_ref.extractall(destination)\n",
        "\n",
        "    # Move the contents of the extracted folder to the destination\n",
        "    extracted_folder = os.path.join(destination, Path(zip_name).stem)\n",
        "    for item in os.listdir(extracted_folder):\n",
        "        s = os.path.join(extracted_folder, item)\n",
        "        d = os.path.join(destination, item)\n",
        "        if os.path.isdir(s):\n",
        "            shutil.move(s, d)\n",
        "        else:\n",
        "            shutil.copy2(s, d)\n",
        "\n",
        "    # Clean up temporary files\n",
        "    #os.remove(zip_name)\n",
        "    shutil.rmtree(extracted_folder)\n",
        "\n",
        "# Download and organize the supervised dataset\n",
        "#download_folder('supervised_data.zip', supervised_dest_dir)\n",
        "\n",
        "# Download and organize the unsupervised dataset\n",
        "download_folder(\"unsupervised_data.zip\", unsupervised_dest_dir)\n",
        "\n",
        "#download_folder(\"unsupervised_synthetic_data.zip\", unsupervised_synthetic_dest_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing duplicate: unsupervised_synthetic/times_unsupervised_images/times-918.jpg\n",
            "Removing duplicate: unsupervised_synthetic/times_unsupervised_images/times-919.jpg\n",
            "Removing duplicate: unsupervised_synthetic/times_unsupervised_images/times-920.jpg\n",
            "Removing duplicate: unsupervised_synthetic/times_unsupervised_images/times-921.jpg\n",
            "Removing duplicate: unsupervised_synthetic/times_unsupervised_images/times-922.jpg\n",
            "Removing duplicate: unsupervised_synthetic/times_unsupervised_images/times-923.jpg\n",
            "Removing duplicate: unsupervised_synthetic/times_unsupervised_images/times-924.jpg\n",
            "Removing duplicate: unsupervised_synthetic/times_unsupervised_images/times-925.jpg\n",
            "Removing duplicate: unsupervised_synthetic/times_unsupervised_images/times-926.jpg\n",
            "Removing duplicate: unsupervised_synthetic/times_unsupervised_images/times-927.jpg\n",
            "Renamed: unsupervised_synthetic/times_unsupervised_images/times-918(1).jpg to unsupervised_synthetic/times_unsupervised_images/times-918.jpg\n",
            "Renamed: unsupervised_synthetic/times_unsupervised_images/times-919(1).jpg to unsupervised_synthetic/times_unsupervised_images/times-919.jpg\n",
            "Renamed: unsupervised_synthetic/times_unsupervised_images/times-920(1).jpg to unsupervised_synthetic/times_unsupervised_images/times-920.jpg\n",
            "Renamed: unsupervised_synthetic/times_unsupervised_images/times-921(1).jpg to unsupervised_synthetic/times_unsupervised_images/times-921.jpg\n",
            "Renamed: unsupervised_synthetic/times_unsupervised_images/times-922(1).jpg to unsupervised_synthetic/times_unsupervised_images/times-922.jpg\n",
            "Renamed: unsupervised_synthetic/times_unsupervised_images/times-923(1).jpg to unsupervised_synthetic/times_unsupervised_images/times-923.jpg\n",
            "Renamed: unsupervised_synthetic/times_unsupervised_images/times-924(1).jpg to unsupervised_synthetic/times_unsupervised_images/times-924.jpg\n",
            "Renamed: unsupervised_synthetic/times_unsupervised_images/times-925(1).jpg to unsupervised_synthetic/times_unsupervised_images/times-925.jpg\n",
            "Renamed: unsupervised_synthetic/times_unsupervised_images/times-926(1).jpg to unsupervised_synthetic/times_unsupervised_images/times-926.jpg\n",
            "Renamed: unsupervised_synthetic/times_unsupervised_images/times-927(1).jpg to unsupervised_synthetic/times_unsupervised_images/times-927.jpg\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import hashlib\n",
        "import shutil\n",
        "\n",
        "def get_file_checksum(file_path):\n",
        "    \"\"\"Calculate the checksum of a file.\"\"\"\n",
        "    sha256_hash = hashlib.sha256()\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        # Read and update hash string value in blocks of 4K\n",
        "        for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
        "            sha256_hash.update(byte_block)\n",
        "    return sha256_hash.hexdigest()\n",
        "\n",
        "def remove_duplicate_images(folder_path):\n",
        "    \"\"\"Remove duplicate images in a folder.\"\"\"\n",
        "    # Dictionary to store checksums and corresponding file paths\n",
        "    checksums = {}\n",
        "\n",
        "    # List all files in the folder\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    for file_name in files:\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        # Check if the file is a regular file and not a directory\n",
        "        if os.path.isfile(file_path):\n",
        "            # Calculate the checksum of the file\n",
        "            checksum = get_file_checksum(file_path)\n",
        "\n",
        "            # Check if the checksum is already in the dictionary\n",
        "            if checksum in checksums:\n",
        "                # If a duplicate is found, remove the file\n",
        "                print(f\"Removing duplicate: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "            else:\n",
        "                # Add the checksum to the dictionary\n",
        "                checksums[checksum] = file_path\n",
        "\n",
        "def rename_files(folder_path):\n",
        "    \"\"\"Rename files with '(1)' in their names.\"\"\"\n",
        "    # List all files in the folder\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    for file_name in files:\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        # Check if the file is a regular file and not a directory\n",
        "        if os.path.isfile(file_path):\n",
        "            # Check if the file name contains '(1)'\n",
        "            if '(1)' in file_name:\n",
        "                # Rename the file by removing '(1)'\n",
        "                new_file_name = file_name.replace('(1)', '')\n",
        "                new_file_path = os.path.join(folder_path, new_file_name)\n",
        "                os.rename(file_path, new_file_path)\n",
        "                print(f\"Renamed: {file_path} to {new_file_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    folder_path = \"unsupervised_synthetic/times_unsupervised_images/\"\n",
        "    remove_duplicate_images(folder_path)\n",
        "    rename_files(folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6zZVhUCht766"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset builder- Supervised"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "class SupervisedDataset(Dataset):\n",
        "    def __init__(self, root_dir, labels_path):\n",
        "        self.root_dir = root_dir\n",
        "        self.labels_path = labels_path\n",
        "        self.data = []\n",
        "        with open(labels_path, newline='') as labels_file:\n",
        "            labels_reader = csv.reader(labels_file)\n",
        "            for row in labels_reader:\n",
        "                self.data.append(row) # a list of [filename, text in image]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root_dir, self.data[idx][0])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.data[idx][1]\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Set your root directory\n",
        "root_dir = 'supervised'\n",
        "#subfolder = 'supervised_data'\n",
        "\n",
        "# Create datasets for each model\n",
        "models = ['arial', 'bradhitc', 'century_schoolbook', 'comic', 'cour', 'papyrus', 'times']\n",
        "train_datasets, val_datasets = [], []\n",
        "\n",
        "for model in models:\n",
        "    model_dir = os.path.join(root_dir, f\"{model}_images\")\n",
        "    labels_path = os.path.join(root_dir, f\"{model}.csv\")\n",
        "    all_data = SupervisedDataset(model_dir, labels.path)\n",
        "    \n",
        "    # Split data into training and validation sets\n",
        "    train_size = 999\n",
        "    val_size = 100\n",
        "    train_data, val_data = torch.utils.data.random_split(all_data, [train_size, val_size])\n",
        "\n",
        "    train_datasets.append(train_data)\n",
        "    val_datasets.append(val_data)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loaders = [DataLoader(dataset, batch_size=32, shuffle=True) for dataset in train_datasets]\n",
        "val_loaders = [DataLoader(dataset, batch_size=32, shuffle=False) for dataset in val_datasets]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset builder - Unsupervised"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Font: arial, Number of samples: 5918\n",
            "Font: bradhitc, Number of samples: 5918\n",
            "Font: century_schoolbook, Number of samples: 5918\n",
            "Font: comic, Number of samples: 5918\n",
            "Font: cour, Number of samples: 5918\n",
            "Font: papyrus, Number of samples: 5918\n",
            "Font: times, Number of samples: 5918\n"
          ]
        }
      ],
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class CustomFontDataset(Dataset):\n",
        "    def __init__(self, root, font_name, transform=None):\n",
        "        self.root = root\n",
        "        self.font_name = font_name\n",
        "        self.transform = transform\n",
        "        self.unsupervised_data = self.load_unsupervised_data()\n",
        "        self.synthetic_data = self.load_synthetic_data()\n",
        "\n",
        "    def load_unsupervised_data(self):\n",
        "        unsupervised_path = os.path.join(self.root, 'unsupervised')\n",
        "        unsupervised_images = [os.path.join(unsupervised_path, img) for img in os.listdir(unsupervised_path)]\n",
        "        return unsupervised_images\n",
        "\n",
        "    def load_synthetic_data(self):\n",
        "        synthetic_path = os.path.join(self.root, f'unsupervised_synthetic/{self.font_name}_unsupervised_images')\n",
        "        synthetic_images = [os.path.join(synthetic_path, img) for img in os.listdir(synthetic_path)]\n",
        "        return synthetic_images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.unsupervised_data) + len(self.synthetic_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index < len(self.unsupervised_data):\n",
        "            img_path = self.unsupervised_data[index]\n",
        "            label = 0  # You can set the label for unsupervised data to 0 or any other value\n",
        "        else:\n",
        "            adjusted_index = index - len(self.unsupervised_data)\n",
        "            img_path = self.synthetic_data[adjusted_index]\n",
        "            label = 1  # You can set the label for synthetic data to 1 or any other value\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Define the transform (you can customize this based on your needs)\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Set root to the current working directory\n",
        "current_working_directory = os.getcwd()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create datasets and dataloaders for each font\n",
        "dataloaders = {}\n",
        "for font_name in models:\n",
        "    font_dataset = CustomFontDataset(root=current_working_directory, font_name=font_name, transform=transform)\n",
        "    font_dataloader = DataLoader(font_dataset, batch_size=32, shuffle=True)\n",
        "    dataloaders[font_name] = font_dataloader\n",
        "\n",
        "# Access each dataloader as needed\n",
        "for font_name, dataloader in dataloaders.items():\n",
        "    print(f\"Font: {font_name}, Number of samples: {len(dataloader.dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4lJFJUkovEba"
      },
      "outputs": [],
      "source": [
        "# Stacked Convolutional Auto-Encoder (the unsupervised sub-network)\n",
        "class SCAE(nn.Module):\n",
        "  def __init__(self, num_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(\n",
        "        in_channels=num_channels,\n",
        "        out_channels=64,\n",
        "        kernel_size=11,\n",
        "        padding=1,\n",
        "        stride=2\n",
        "    )\n",
        "    self.conv2 = nn.Conv2d(\n",
        "        in_channels=64,\n",
        "        out_channels=128,\n",
        "        kernel_size=5,\n",
        "        padding=2\n",
        "    )\n",
        "    self.deconv1 = nn.ConvTranspose2d(\n",
        "        in_channels = 128,\n",
        "        out_channels = 64,\n",
        "        kernel_size = 5,\n",
        "        padding = 2\n",
        "    )\n",
        "    self.deconv2 = nn.ConvTranspose2d(\n",
        "        in_channels=64,\n",
        "        out_channels=1,\n",
        "        kernel_size=11,\n",
        "        padding=1,\n",
        "        stride=2\n",
        "    )\n",
        "    self.maxpool = nn.MaxPool2d(2, return_indices=True)\n",
        "    self.unpool = nn.MaxUnpool2d(2)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.conv1(x)\n",
        "    self.maxpool(x)\n",
        "    self.relu(x)\n",
        "\n",
        "    self.conv2(x)\n",
        "    self.relu(x)\n",
        "\n",
        "    self.deconv1(x)\n",
        "    self.unpool(x)\n",
        "    self.relu(x)\n",
        "\n",
        "    self.deconv2(x)\n",
        "    self.relu(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtnGJaRkS1L5"
      },
      "outputs": [],
      "source": [
        "class DeepFont(nn.Module):\n",
        "  def __init__(self, num_channels, num_classes):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(\n",
        "        in_channels=num_channels,\n",
        "        out_channels=64,\n",
        "        kernel_size=11,\n",
        "        padding=1,\n",
        "        stride=2\n",
        "    )\n",
        "    self.conv2 = nn.Conv2d(\n",
        "        in_channels=64,\n",
        "        out_channels=128,\n",
        "        kernel_size=5,\n",
        "        padding=2\n",
        "    )\n",
        "    self.conv3 = nn.Conv2d(\n",
        "        in_channels=128,\n",
        "        out_channels=256,\n",
        "        kernel_size=3,\n",
        "        padding=1\n",
        "    )\n",
        "    self.conv4 = nn.Conv2d(\n",
        "        in_channels=256,\n",
        "        out_channels=256,\n",
        "        kernel_size=3,\n",
        "        padding=1\n",
        "    )\n",
        "    self.conv5 = self.conv4\n",
        "    self.fc6 = nn.Linear(in_features=12*12*256, out_features=4096) # assuming input image size of 105. change in_feats for different sample size\n",
        "    self.fc7 = nn.Linear(in_features=4096, out_features=4096)\n",
        "    self.fc8 = nn.Linear(in_features=4096, out_features=num_classes)\n",
        "    self.norm1 = nn.BatchNorm2d(num_features=64)\n",
        "    self.norm2 = nn.BatchNorm2d(num_features=128)\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "    self.maxpool = nn.MaxPool2d(2)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.softmax = nn.Softmax()\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.conv1(x)\n",
        "    self.norm1(x)\n",
        "    self.maxpool(x)\n",
        "    self.relu(x)\n",
        "\n",
        "    self.conv2(x)\n",
        "    self.norm2(x)\n",
        "    self.maxpool(x)\n",
        "    self.relu(x)\n",
        "\n",
        "    self.conv3(x)\n",
        "    self.relu(x)\n",
        "\n",
        "    self.conv4(x)\n",
        "    self.relu(x)\n",
        "\n",
        "    self.conv5(x)\n",
        "    self.relu(x)\n",
        "\n",
        "    self.flatten(x)\n",
        "\n",
        "    self.dropout(self.fc6(x))\n",
        "    self.relu(x)\n",
        "\n",
        "    self.dropout(self.fc7(x))\n",
        "    self.relu(x)\n",
        "\n",
        "    self.fc8(x)\n",
        "    self.relu(x)\n",
        "\n",
        "    self.softmax(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def training_unsupervised(model, dataloader, criterion, optimizer, device, epochs, model_path):\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    best_loss = torch.inf\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch_index, (images, _) in enumerate(loader):\n",
        "            optimizer.zero_grad()\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, images)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        avg_loss = total_loss / (batch_index+1)\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            torch.save(model.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Supervised model training function adapted from code provided by Dr. Farhad Maleki in MNISTFasion_CNN.ipynb\n",
        "def training_supervised(model, train_loader, val_loader, criterion, optimizer, device,\n",
        "             epochs, best_model_path):\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    best_loss = torch.inf\n",
        "    best_results = None\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        total  = 0\n",
        "        correct = 0\n",
        "        for batch_index, (images, labels) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            total += images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "        accuracy = correct / total\n",
        "        loss = total_loss / total\n",
        "        print(f'{epoch:<4} Train Accuracy={accuracy:<10.4f}  Loss= {loss:<10.4f}')\n",
        "        results = evaluation(model, val_loader, criterion, device)\n",
        "        if results['loss'] < best_loss:\n",
        "            torch.save(model, best_model_path)\n",
        "            best_loss = results['loss']\n",
        "            best_results = results\n",
        "        print()\n",
        "    return best_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "models_dir = 'models'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Train the unsupervised sub-network\n",
        "# Hyperparameters\n",
        "learning_rate = 0.01\n",
        "momentum = 0.9\n",
        "weight_decay = 5e-4\n",
        "epochs = 10\n",
        "\n",
        "scae_model = SCAE(num_channels=3)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(scae_model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "for font_name, dataloader in dataloaders.items():\n",
        "    model_path = os.path.join(models_dir, f\"{font_name}_SCAE.pt\")\n",
        "    training_unsupervised(scae_model, dataloader, criterion, optimizer, device, epochs, model_path)\n",
        "\n",
        "# Train the supervised sub-network\n",
        "supervised_model = DeepFont(num_channels=3, num_classes=1099) # each image contains a unique word, so each is its own class\n",
        "for i in range(len(models)):\n",
        "    font_name = models[i]\n",
        "\n",
        "    # Import the convolutional layers of the SCAE as conv1 and conv2\n",
        "    scae_path = os.path.join(models_dir, f\"{font_name}_SCAE.pt\")\n",
        "    supervised_model.load_state_dict(torch.load(scae_path), strict=False)\n",
        "    train_loader = train_loaders[i]\n",
        "    val_loader = val_loaders[i]\n",
        "    best_model_path = os.path.join(models_dir, f\"{font_name}_model.pt\")\n",
        "    best_results = training_supervised(model, train_loader, val_loader, criterion, optimizer, device, epochs, best_model_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
